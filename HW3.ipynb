{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>85 84 90 121 101 102 133 153 153 169 177 189 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>255 254 255 254 254 179 122 107 95 124 149 150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>30 24 21 23 25 25 49 67 84 103 120 125 130 139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>39 75 78 58 58 45 49 48 103 156 81 45 41 38 49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>219 213 206 202 209 217 216 215 219 218 223 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>148 144 130 129 119 122 129 131 139 153 140 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>4 2 13 41 56 62 67 87 95 62 65 70 80 107 127 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>107 107 109 109 109 109 110 101 123 140 144 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>14 14 18 28 27 22 21 30 42 61 77 86 88 95 100 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>255 255 255 255 255 255 255 255 255 255 255 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>134 124 167 180 197 194 203 210 204 203 209 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>219 192 179 148 208 254 192 98 121 103 145 185...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 7 12 23 45 38 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>174 51 37 37 38 41 22 25 22 24 35 51 70 83 98 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>123 125 124 142 209 226 234 236 231 232 235 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>8 9 14 21 26 32 37 46 52 62 72 70 71 73 76 83 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>252 250 246 229 182 140 98 72 53 44 67 95 95 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>224 227 219 217 215 210 187 177 189 200 206 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>162 200 187 180 197 198 196 192 176 152 136 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>236 230 225 226 228 209 199 193 196 211 199 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>210 210 210 210 211 207 147 103 68 60 47 70 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>50 44 74 141 187 187 169 113 80 128 181 172 76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28679</th>\n",
       "      <td>6</td>\n",
       "      <td>39 39 39 39 38 30 41 63 105 117 84 97 101 75 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28680</th>\n",
       "      <td>4</td>\n",
       "      <td>137 146 153 157 164 166 169 172 177 176 176 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28681</th>\n",
       "      <td>6</td>\n",
       "      <td>208 207 205 206 207 207 210 211 210 207 211 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28682</th>\n",
       "      <td>2</td>\n",
       "      <td>10 10 10 10 10 10 10 10 10 10 12 2 45 117 122 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28683</th>\n",
       "      <td>4</td>\n",
       "      <td>178 142 131 130 145 152 125 92 115 142 149 158...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28684</th>\n",
       "      <td>3</td>\n",
       "      <td>80 94 86 71 98 74 46 67 105 71 63 76 51 53 80 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28685</th>\n",
       "      <td>4</td>\n",
       "      <td>94 92 91 92 93 93 92 92 90 90 61 41 34 37 52 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28686</th>\n",
       "      <td>0</td>\n",
       "      <td>178 184 187 195 199 194 197 205 202 194 201 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28687</th>\n",
       "      <td>3</td>\n",
       "      <td>114 100 121 166 185 175 160 174 195 205 216 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28688</th>\n",
       "      <td>3</td>\n",
       "      <td>30 47 52 25 29 48 46 41 70 63 66 49 37 41 35 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28689</th>\n",
       "      <td>3</td>\n",
       "      <td>181 178 179 171 78 51 56 46 48 50 54 54 68 96 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28690</th>\n",
       "      <td>2</td>\n",
       "      <td>186 182 173 164 164 177 91 45 66 72 79 79 85 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28691</th>\n",
       "      <td>4</td>\n",
       "      <td>255 255 255 255 255 255 255 255 255 255 255 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28692</th>\n",
       "      <td>3</td>\n",
       "      <td>99 103 106 109 112 113 115 118 120 121 115 83 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28693</th>\n",
       "      <td>6</td>\n",
       "      <td>216 219 216 209 181 104 128 129 134 136 135 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28694</th>\n",
       "      <td>3</td>\n",
       "      <td>159 195 167 158 152 150 149 154 154 151 149 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28695</th>\n",
       "      <td>2</td>\n",
       "      <td>84 96 110 132 165 183 175 154 116 95 75 67 63 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28696</th>\n",
       "      <td>4</td>\n",
       "      <td>0 0 1 1 7 35 76 87 86 90 87 83 89 92 92 93 98 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28697</th>\n",
       "      <td>3</td>\n",
       "      <td>181 172 161 144 116 109 70 109 187 131 67 30 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28698</th>\n",
       "      <td>3</td>\n",
       "      <td>35 45 69 79 75 48 45 35 56 93 71 51 48 47 46 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28699</th>\n",
       "      <td>6</td>\n",
       "      <td>128 134 164 94 70 114 159 138 75 47 89 127 134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28700</th>\n",
       "      <td>4</td>\n",
       "      <td>11 10 12 13 9 11 10 11 11 10 10 13 11 10 11 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28701</th>\n",
       "      <td>2</td>\n",
       "      <td>34 42 47 34 53 41 33 39 42 38 40 44 41 42 42 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28702</th>\n",
       "      <td>0</td>\n",
       "      <td>196 194 188 177 156 124 81 60 65 64 84 119 114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28703</th>\n",
       "      <td>5</td>\n",
       "      <td>255 255 255 255 255 255 255 203 145 147 143 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28704</th>\n",
       "      <td>2</td>\n",
       "      <td>84 85 85 85 85 85 85 85 86 86 86 87 86 86 91 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28705</th>\n",
       "      <td>0</td>\n",
       "      <td>114 112 113 113 111 111 112 113 115 113 114 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28706</th>\n",
       "      <td>4</td>\n",
       "      <td>74 81 87 89 95 100 98 93 105 120 127 133 146 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>0</td>\n",
       "      <td>222 227 203 90 86 90 84 77 94 87 99 119 134 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28708</th>\n",
       "      <td>4</td>\n",
       "      <td>195 199 205 206 205 203 206 209 208 210 212 21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28709 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            feature\n",
       "0          0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1          0  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2          2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3          4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4          6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...\n",
       "5          2  55 55 55 55 55 54 60 68 54 85 151 163 170 179 ...\n",
       "6          4  20 17 19 21 25 38 42 42 46 54 56 62 63 66 82 1...\n",
       "7          3  77 78 79 79 78 75 60 55 47 48 58 73 77 79 57 5...\n",
       "8          3  85 84 90 121 101 102 133 153 153 169 177 189 1...\n",
       "9          2  255 254 255 254 254 179 122 107 95 124 149 150...\n",
       "10         0  30 24 21 23 25 25 49 67 84 103 120 125 130 139...\n",
       "11         6  39 75 78 58 58 45 49 48 103 156 81 45 41 38 49...\n",
       "12         6  219 213 206 202 209 217 216 215 219 218 223 23...\n",
       "13         6  148 144 130 129 119 122 129 131 139 153 140 12...\n",
       "14         3  4 2 13 41 56 62 67 87 95 62 65 70 80 107 127 1...\n",
       "15         5  107 107 109 109 109 109 110 101 123 140 144 14...\n",
       "16         3  14 14 18 28 27 22 21 30 42 61 77 86 88 95 100 ...\n",
       "17         2  255 255 255 255 255 255 255 255 255 255 255 25...\n",
       "18         6  134 124 167 180 197 194 203 210 204 203 209 20...\n",
       "19         4  219 192 179 148 208 254 192 98 121 103 145 185...\n",
       "20         4  1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 7 12 23 45 38 ...\n",
       "21         2  174 51 37 37 38 41 22 25 22 24 35 51 70 83 98 ...\n",
       "22         0  123 125 124 142 209 226 234 236 231 232 235 22...\n",
       "23         0  8 9 14 21 26 32 37 46 52 62 72 70 71 73 76 83 ...\n",
       "24         3  252 250 246 229 182 140 98 72 53 44 67 95 95 8...\n",
       "25         3  224 227 219 217 215 210 187 177 189 200 206 21...\n",
       "26         5  162 200 187 180 197 198 196 192 176 152 136 11...\n",
       "27         0  236 230 225 226 228 209 199 193 196 211 199 19...\n",
       "28         3  210 210 210 210 211 207 147 103 68 60 47 70 12...\n",
       "29         5  50 44 74 141 187 187 169 113 80 128 181 172 76...\n",
       "...      ...                                                ...\n",
       "28679      6  39 39 39 39 38 30 41 63 105 117 84 97 101 75 5...\n",
       "28680      4  137 146 153 157 164 166 169 172 177 176 176 17...\n",
       "28681      6  208 207 205 206 207 207 210 211 210 207 211 21...\n",
       "28682      2  10 10 10 10 10 10 10 10 10 10 12 2 45 117 122 ...\n",
       "28683      4  178 142 131 130 145 152 125 92 115 142 149 158...\n",
       "28684      3  80 94 86 71 98 74 46 67 105 71 63 76 51 53 80 ...\n",
       "28685      4  94 92 91 92 93 93 92 92 90 90 61 41 34 37 52 6...\n",
       "28686      0  178 184 187 195 199 194 197 205 202 194 201 20...\n",
       "28687      3  114 100 121 166 185 175 160 174 195 205 216 22...\n",
       "28688      3  30 47 52 25 29 48 46 41 70 63 66 49 37 41 35 3...\n",
       "28689      3  181 178 179 171 78 51 56 46 48 50 54 54 68 96 ...\n",
       "28690      2  186 182 173 164 164 177 91 45 66 72 79 79 85 1...\n",
       "28691      4  255 255 255 255 255 255 255 255 255 255 255 25...\n",
       "28692      3  99 103 106 109 112 113 115 118 120 121 115 83 ...\n",
       "28693      6  216 219 216 209 181 104 128 129 134 136 135 14...\n",
       "28694      3  159 195 167 158 152 150 149 154 154 151 149 14...\n",
       "28695      2  84 96 110 132 165 183 175 154 116 95 75 67 63 ...\n",
       "28696      4  0 0 1 1 7 35 76 87 86 90 87 83 89 92 92 93 98 ...\n",
       "28697      3  181 172 161 144 116 109 70 109 187 131 67 30 2...\n",
       "28698      3  35 45 69 79 75 48 45 35 56 93 71 51 48 47 46 4...\n",
       "28699      6  128 134 164 94 70 114 159 138 75 47 89 127 134...\n",
       "28700      4  11 10 12 13 9 11 10 11 11 10 10 13 11 10 11 10...\n",
       "28701      2  34 42 47 34 53 41 33 39 42 38 40 44 41 42 42 4...\n",
       "28702      0  196 194 188 177 156 124 81 60 65 64 84 119 114...\n",
       "28703      5  255 255 255 255 255 255 255 203 145 147 143 14...\n",
       "28704      2  84 85 85 85 85 85 85 85 86 86 86 87 86 86 91 9...\n",
       "28705      0  114 112 113 113 111 111 112 113 115 113 114 11...\n",
       "28706      4  74 81 87 89 95 100 98 93 105 120 127 133 146 1...\n",
       "28707      0  222 227 203 90 86 90 84 77 94 87 99 119 134 14...\n",
       "28708      4  195 199 205 206 205 203 206 209 208 210 212 21...\n",
       "\n",
       "[28709 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR_MAC=\"/Users/haipengwu/Codings/Machine Learning/HW3/\"\n",
    "DIR_1080=\"C:\\\\Users\\\\WIN10\\\\Codings\\\\Machine Learning\\\\HW3\\\\\"\n",
    "\n",
    "FILE_X_train=\"train.csv\"\n",
    "# FILE_y_train=\"Y_train\"\n",
    "FILE_X_test=\"test.csv\"\n",
    "\n",
    "#put directory info inside Run_machine\n",
    "RUN_MACHINE =DIR_1080\n",
    "\n",
    "\n",
    "df_X_train = pd.read_csv(RUN_MACHINE+FILE_X_train, encoding='unicode_escape' ,sep=',',engine='python')\n",
    "\n",
    "df_X_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split to X_train and X_val because fit_generator has no validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.array(df_X_train)\n",
    "\n",
    "training_num = 26000\n",
    "validation_num = training_data.shape[0] - training_num\n",
    "\n",
    "X_train=np.empty([training_num,48*48])\n",
    "y_train =np.empty([training_num,1])\n",
    "\n",
    "X_val=np.empty([validation_num,48*48])\n",
    "y_val=np.empty([validation_num,1])\n",
    "\n",
    "for i in range(training_data.shape[0]):\n",
    "    if i<training_num:\n",
    "        X_train[i]=training_data[i][1].split()\n",
    "        y_train[i] = training_data[i][0]\n",
    "    else:\n",
    "        X_val[i - training_num]= training_data[i][1].split()\n",
    "        y_val[i - training_num] = training_data[i][0]\n",
    "\n",
    "X_train = X_train.reshape(-1,48,48)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "\n",
    "X_val = X_val.reshape(-1,48,48)\n",
    "y_val = y_val.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.imshow(X_train[0])\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "# plt.imshow(X_val[0])\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation and image data normalization using rescale parameter\n",
    "# Convert from Grayscale to RGB format for LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "import skimage\n",
    "\n",
    "X_train = skimage.color.gray2rgb(X_train)\n",
    "X_val = skimage.color.gray2rgb(X_val)\n",
    "\n",
    "#X_train = X_train.reshape(-1,48,48,1)\n",
    "#X_val = X_val.reshape(-1,48,48,1)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #samplewise_center=True,\n",
    "    #samplewise_std_normalization=True,\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "#     zca_epsilon = 0.1,\n",
    "#     fill_mode = 'nearest',\n",
    "#     zca_whitening = True,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "\n",
    "# photoshop X_train by datagen\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "#     zca_epsilon = 0.1,\n",
    "#     zca_whitening = True)    \n",
    "     #samplewise_center=True,\n",
    "     #samplewise_std_normalization=True)\n",
    "#      featurewise_center=True,\n",
    "#      featurewise_std_normalization=True)\n",
    "\n",
    "val_datagen.fit(X_val)\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 7\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "validation_generator = val_datagen.flow(X_val,y_val,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check some of the modified pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for batch in datagen.flow(X_train, batch_size=1,\n",
    "#                           save_to_dir='preview', save_prefix='emoji', save_format='jpeg'):\n",
    "#     i += 1\n",
    "#     if i > 20:\n",
    "#         break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Conv2D,Flatten,BatchNormalization,LeakyReLU,Dropout, MaxPooling2D,Conv1D,ReLU,PReLU\n",
    "from keras.optimizers import RMSprop,Adam,SGD,Adagrad,Nadam,Adadelta\n",
    "from keras.utils import np_utils #,normalize\n",
    "from keras import regularizers\n",
    "import numpy as np\n",
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\WIN10\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\WIN10\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 903       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,047,207\n",
      "Trainable params: 1,044,775\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l2_para=0\n",
    "\n",
    "Layers_Feature_Map=[32,64,128,128]\n",
    "Fully_Connected_Layers=[128,128]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(BatchNormalization(momentum=.5, input_shape=X_train[0].shape))\n",
    "\n",
    "model.add(Conv2D(Layers_Feature_Map[0],kernel_size=3,strides = 1,padding='SAME', input_shape=X_train[0].shape))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(Layers_Feature_Map[0],kernel_size=3,strides = 1,padding='SAME',))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=.5))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(Layers_Feature_Map[1],kernel_size=3,strides = 1,padding='SAME'))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(Layers_Feature_Map[1],kernel_size=3,strides = 1,padding='SAME'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=.5))\n",
    "\n",
    "model.add(Conv2D(Layers_Feature_Map[2],kernel_size=3,strides = 1,padding='SAME'))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(Layers_Feature_Map[2],kernel_size=3,strides = 1,padding='SAME'))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(Layers_Feature_Map[2],kernel_size=3,strides = 1,padding='SAME'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=.5))\n",
    "\n",
    "model.add(Conv2D(Layers_Feature_Map[3],kernel_size=3,strides = 1,padding='SAME'))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(Layers_Feature_Map[3],kernel_size=3,strides = 1,padding='SAME'))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(Layers_Feature_Map[3],kernel_size=3,strides = 1,padding='SAME'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(Fully_Connected_Layers[0],kernel_regularizer=regularizers.l2(l2_para)))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=.5))\n",
    "\n",
    "model.add(Dense(Fully_Connected_Layers[1],kernel_regularizer=regularizers.l2(l2_para)))\n",
    "model.add(BatchNormalization(momentum=.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=.5))\n",
    "\n",
    "model.add(Dense(7,kernel_regularizer=regularizers.l2(l2_para)))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Xception model directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import applications\n",
    "\n",
    "# model = applications.xception.Xception(include_top = False, weights='imagenet',input_shape=X_train[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set loss,optimizer and compile the model, use Adam，loss use category cross-entropy,training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1d47b6149e11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# optimizer =RMSprop(0.00005)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# optimizer =Adam()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#optimizer = Adadelta()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# optimizer =RMSprop(0.00005)\n",
    "# optimizer =Adam()\n",
    "optimizer=Adam(0.001,0.8)\n",
    "#optimizer = Adadelta()\n",
    "loss=\"categorical_crossentropy\"\n",
    "epochs=100\n",
    "model.reset_states()\n",
    "model.compile(\n",
    "        optimizer, \n",
    "        loss=loss,\n",
    "        metrics=[loss,'accuracy']\n",
    "        )\n",
    "\n",
    "# set tensorboard\n",
    "NAME = \"emoji-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "# training the network\n",
    "\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),  steps_per_epoch=len(X_train) / BATCH_SIZE, epochs=epochs,\\\n",
    "                    shuffle=True,callbacks = [tensorboard],validation_data = validation_generator,validation_steps=len(X_val) / BATCH_SIZE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "204/203 [==============================] - 16s 79ms/step - loss: 0.8696 - categorical_crossentropy: 0.8696 - acc: 0.6818 - val_loss: 0.8950 - val_categorical_crossentropy: 0.8950 - val_acc: 0.6718\n",
      "Epoch 2/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8605 - categorical_crossentropy: 0.8605 - acc: 0.6829 - val_loss: 0.9898 - val_categorical_crossentropy: 0.9898 - val_acc: 0.6733\n",
      "Epoch 3/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8654 - categorical_crossentropy: 0.8654 - acc: 0.6828 - val_loss: 0.9084 - val_categorical_crossentropy: 0.9084 - val_acc: 0.6781\n",
      "Epoch 4/100\n",
      "204/203 [==============================] - 13s 63ms/step - loss: 0.8634 - categorical_crossentropy: 0.8634 - acc: 0.6823 - val_loss: 0.8885 - val_categorical_crossentropy: 0.8885 - val_acc: 0.6748\n",
      "Epoch 5/100\n",
      "204/203 [==============================] - 13s 63ms/step - loss: 0.8671 - categorical_crossentropy: 0.8671 - acc: 0.6832 - val_loss: 0.9869 - val_categorical_crossentropy: 0.9869 - val_acc: 0.6597\n",
      "Epoch 6/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8629 - categorical_crossentropy: 0.8629 - acc: 0.6836 - val_loss: 0.9068 - val_categorical_crossentropy: 0.9068 - val_acc: 0.6788tegorical_crossentropy: 0.8582 - acc:  - ETA: 0s - loss: 0.8582 - categorical_crossentro\n",
      "Epoch 7/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8690 - categorical_crossentropy: 0.8690 - acc: 0.6822 - val_loss: 0.9159 - val_categorical_crossentropy: 0.9159 - val_acc: 0.6785\n",
      "Epoch 8/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8613 - categorical_crossentropy: 0.8613 - acc: 0.6851 - val_loss: 0.9362 - val_categorical_crossentropy: 0.9362 - val_acc: 0.6678\n",
      "Epoch 9/100\n",
      "204/203 [==============================] - 13s 63ms/step - loss: 0.8561 - categorical_crossentropy: 0.8561 - acc: 0.6841 - val_loss: 0.9083 - val_categorical_crossentropy: 0.9083 - val_acc: 0.6744\n",
      "Epoch 10/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8582 - categorical_crossentropy: 0.8582 - acc: 0.6841 - val_loss: 0.9009 - val_categorical_crossentropy: 0.9009 - val_acc: 0.6670\n",
      "Epoch 11/100\n",
      "204/203 [==============================] - 13s 63ms/step - loss: 0.8580 - categorical_crossentropy: 0.8580 - acc: 0.6831 - val_loss: 0.9535 - val_categorical_crossentropy: 0.9535 - val_acc: 0.6630\n",
      "Epoch 12/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8581 - categorical_crossentropy: 0.8581 - acc: 0.6865 - val_loss: 0.8974 - val_categorical_crossentropy: 0.8974 - val_acc: 0.6818\n",
      "Epoch 13/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8578 - categorical_crossentropy: 0.8578 - acc: 0.6836 - val_loss: 0.9258 - val_categorical_crossentropy: 0.9258 - val_acc: 0.6777\n",
      "Epoch 14/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8543 - categorical_crossentropy: 0.8543 - acc: 0.6859 - val_loss: 0.8934 - val_categorical_crossentropy: 0.8934 - val_acc: 0.6752\n",
      "Epoch 15/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8481 - categorical_crossentropy: 0.8481 - acc: 0.6849 - val_loss: 0.9049 - val_categorical_crossentropy: 0.9049 - val_acc: 0.6829\n",
      "Epoch 16/100\n",
      "204/203 [==============================] - 13s 63ms/step - loss: 0.8568 - categorical_crossentropy: 0.8568 - acc: 0.6833 - val_loss: 0.9296 - val_categorical_crossentropy: 0.9296 - val_acc: 0.6766\n",
      "Epoch 17/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8607 - categorical_crossentropy: 0.8607 - acc: 0.6825 - val_loss: 0.9129 - val_categorical_crossentropy: 0.9129 - val_acc: 0.6777\n",
      "Epoch 18/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8562 - categorical_crossentropy: 0.8562 - acc: 0.6823 - val_loss: 1.0060 - val_categorical_crossentropy: 1.0060 - val_acc: 0.6648\n",
      "Epoch 19/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8581 - categorical_crossentropy: 0.8581 - acc: 0.6839 - val_loss: 0.9319 - val_categorical_crossentropy: 0.9319 - val_acc: 0.6752\n",
      "Epoch 20/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8456 - categorical_crossentropy: 0.8456 - acc: 0.6873 - val_loss: 0.9558 - val_categorical_crossentropy: 0.9558 - val_acc: 0.6800\n",
      "Epoch 21/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8470 - categorical_crossentropy: 0.8470 - acc: 0.6852 - val_loss: 0.8913 - val_categorical_crossentropy: 0.8913 - val_acc: 0.6781\n",
      "Epoch 22/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8521 - categorical_crossentropy: 0.8521 - acc: 0.6874 - val_loss: 0.9276 - val_categorical_crossentropy: 0.9276 - val_acc: 0.6814\n",
      "Epoch 23/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8407 - categorical_crossentropy: 0.8407 - acc: 0.6907 - val_loss: 0.9731 - val_categorical_crossentropy: 0.9731 - val_acc: 0.6663\n",
      "Epoch 24/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8447 - categorical_crossentropy: 0.8447 - acc: 0.6893 - val_loss: 0.9611 - val_categorical_crossentropy: 0.9611 - val_acc: 0.6785\n",
      "Epoch 25/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8498 - categorical_crossentropy: 0.8498 - acc: 0.6872 - val_loss: 0.9529 - val_categorical_crossentropy: 0.9529 - val_acc: 0.6689\n",
      "Epoch 26/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8378 - categorical_crossentropy: 0.8378 - acc: 0.6922 - val_loss: 0.9261 - val_categorical_crossentropy: 0.9261 - val_acc: 0.6667\n",
      "Epoch 27/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8418 - categorical_crossentropy: 0.8418 - acc: 0.6881 - val_loss: 0.8970 - val_categorical_crossentropy: 0.8970 - val_acc: 0.6814\n",
      "Epoch 28/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8448 - categorical_crossentropy: 0.8448 - acc: 0.6885 - val_loss: 0.9035 - val_categorical_crossentropy: 0.9035 - val_acc: 0.6759\n",
      "Epoch 29/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8443 - categorical_crossentropy: 0.8443 - acc: 0.6876 - val_loss: 0.9187 - val_categorical_crossentropy: 0.9187 - val_acc: 0.6766\n",
      "Epoch 30/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8422 - categorical_crossentropy: 0.8422 - acc: 0.6885 - val_loss: 0.9291 - val_categorical_crossentropy: 0.9291 - val_acc: 0.6674\n",
      "Epoch 31/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8420 - categorical_crossentropy: 0.8420 - acc: 0.6882 - val_loss: 0.9217 - val_categorical_crossentropy: 0.9217 - val_acc: 0.6781\n",
      "Epoch 32/100\n",
      "204/203 [==============================] - 14s 66ms/step - loss: 0.8367 - categorical_crossentropy: 0.8367 - acc: 0.6936 - val_loss: 0.9313 - val_categorical_crossentropy: 0.9313 - val_acc: 0.6630\n",
      "Epoch 33/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8352 - categorical_crossentropy: 0.8352 - acc: 0.6920 - val_loss: 0.9771 - val_categorical_crossentropy: 0.9771 - val_acc: 0.6626\n",
      "Epoch 34/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8420 - categorical_crossentropy: 0.8420 - acc: 0.6895 - val_loss: 0.9523 - val_categorical_crossentropy: 0.9523 - val_acc: 0.6681\n",
      "Epoch 35/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8331 - categorical_crossentropy: 0.8331 - acc: 0.6933 - val_loss: 0.9690 - val_categorical_crossentropy: 0.9690 - val_acc: 0.6652\n",
      "Epoch 36/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8332 - categorical_crossentropy: 0.8332 - acc: 0.6899 - val_loss: 0.9487 - val_categorical_crossentropy: 0.9487 - val_acc: 0.6604\n",
      "Epoch 37/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8368 - categorical_crossentropy: 0.8368 - acc: 0.6921 - val_loss: 1.0323 - val_categorical_crossentropy: 1.0323 - val_acc: 0.6641\n",
      "Epoch 38/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8420 - categorical_crossentropy: 0.8420 - acc: 0.6893 - val_loss: 0.9853 - val_categorical_crossentropy: 0.9853 - val_acc: 0.6645\n",
      "Epoch 39/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8398 - categorical_crossentropy: 0.8398 - acc: 0.6932 - val_loss: 0.9101 - val_categorical_crossentropy: 0.9101 - val_acc: 0.6796\n",
      "Epoch 40/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8336 - categorical_crossentropy: 0.8336 - acc: 0.6939 - val_loss: 0.9118 - val_categorical_crossentropy: 0.9118 - val_acc: 0.6777\n",
      "Epoch 41/100\n",
      "204/203 [==============================] - 13s 66ms/step - loss: 0.8323 - categorical_crossentropy: 0.8323 - acc: 0.6930 - val_loss: 0.9602 - val_categorical_crossentropy: 0.9602 - val_acc: 0.6641\n",
      "Epoch 42/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8318 - categorical_crossentropy: 0.8318 - acc: 0.6927 - val_loss: 0.9936 - val_categorical_crossentropy: 0.9936 - val_acc: 0.6670\n",
      "Epoch 43/100\n",
      "204/203 [==============================] - 14s 66ms/step - loss: 0.8312 - categorical_crossentropy: 0.8312 - acc: 0.6944 - val_loss: 0.9783 - val_categorical_crossentropy: 0.9783 - val_acc: 0.6604\n",
      "Epoch 44/100\n",
      "204/203 [==============================] - 14s 66ms/step - loss: 0.8311 - categorical_crossentropy: 0.8311 - acc: 0.6947 - val_loss: 0.9674 - val_categorical_crossentropy: 0.9674 - val_acc: 0.6722\n",
      "Epoch 45/100\n",
      "204/203 [==============================] - 13s 62ms/step - loss: 0.8294 - categorical_crossentropy: 0.8294 - acc: 0.6950 - val_loss: 0.9312 - val_categorical_crossentropy: 0.9312 - val_acc: 0.6752\n",
      "Epoch 46/100\n",
      "204/203 [==============================] - 13s 64ms/step - loss: 0.8264 - categorical_crossentropy: 0.8264 - acc: 0.6994 - val_loss: 1.0091 - val_categorical_crossentropy: 1.0091 - val_acc: 0.6578\n",
      "Epoch 47/100\n",
      "204/203 [==============================] - 13s 63ms/step - loss: 0.8310 - categorical_crossentropy: 0.8310 - acc: 0.6942 - val_loss: 0.9893 - val_categorical_crossentropy: 0.9893 - val_acc: 0.6597\n",
      "Epoch 48/100\n",
      "204/203 [==============================] - 13s 65ms/step - loss: 0.8394 - categorical_crossentropy: 0.8394 - acc: 0.6916 - val_loss: 0.9695 - val_categorical_crossentropy: 0.9695 - val_acc: 0.6637\n",
      "Epoch 49/100\n",
      "200/203 [============================>.] - ETA: 0s - loss: 0.8314 - categorical_crossentropy: 0.8314 - acc: 0.6920"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-52c42ae99e4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit_generator(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),  steps_per_epoch=len(X_train) / BATCH_SIZE, epochs=100,\\\n\u001b[1;32m----> 2\u001b[1;33m                   shuffle=True,callbacks = [tensorboard],validation_data = validation_generator,validation_steps=len(X_val) / BATCH_SIZE)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),  steps_per_epoch=len(X_train) / BATCH_SIZE, epochs=100,\\\n",
    "                  shuffle=True,callbacks = [tensorboard],validation_data = validation_generator,validation_steps=len(X_val) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_NAME= \"emoji-rgb.h5\"\n",
    "model.save(SAVE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make prediction with saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#change the name if needed\n",
    "#SAVE_NAME = \"emoji.h5\"\n",
    "model = load_model(SAVE_NAME)\n",
    "\n",
    "df_X_test = pd.read_csv(RUN_MACHINE+FILE_X_test, encoding='unicode_escape',sep=',',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = np.array(df_X_test)\n",
    "\n",
    "X_test=np.empty([testing_data.shape[0],48*48])\n",
    "for i in range(testing_data.shape[0]):\n",
    "    X_test[i]=testing_data[i][1].split()\n",
    "X_test = X_test.reshape(-1,48,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "X_test = skimage.color.gray2rgb(X_test)\n",
    "#X_test = X_test.reshape(-1,48,48,1)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)\n",
    "#     zca_epsilon = 0.1,\n",
    "#     zca_whitening = True)\n",
    "     #samplewise_center=True,\n",
    "     #samplewise_std_normalization=True)\n",
    "#      featurewise_center=True,\n",
    "#     featurewise_std_normalization=True)\n",
    "\n",
    "test_datagen.fit(X_test)\n",
    "test_generator = test_datagen.flow(X_test, shuffle=False, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7178, 1)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict_generator(test_generator, steps = X_test.shape[0] / BATCH_SIZE)\n",
    "\n",
    "y_test_pred = np.argmax(y_test_pred,axis=1)\n",
    "y_test_pred =y_test_pred.reshape(-1,1)\n",
    "print(y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7178, 1) (7178, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7148</th>\n",
       "      <td>7148</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7149</th>\n",
       "      <td>7149</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>7150</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7151</th>\n",
       "      <td>7151</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>7152</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>7153</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7154</th>\n",
       "      <td>7154</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7155</th>\n",
       "      <td>7155</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7156</th>\n",
       "      <td>7156</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>7157</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158</th>\n",
       "      <td>7158</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7159</th>\n",
       "      <td>7159</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7160</th>\n",
       "      <td>7160</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7161</th>\n",
       "      <td>7161</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7162</th>\n",
       "      <td>7162</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7163</th>\n",
       "      <td>7163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7164</th>\n",
       "      <td>7164</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7165</th>\n",
       "      <td>7165</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7166</th>\n",
       "      <td>7166</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7167</th>\n",
       "      <td>7167</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>7168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7169</th>\n",
       "      <td>7169</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>7170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>7171</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>7172</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>7173</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7174</th>\n",
       "      <td>7174</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7175</th>\n",
       "      <td>7175</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7176</th>\n",
       "      <td>7176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>7177</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7178 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label\n",
       "0        0      3\n",
       "1        1      3\n",
       "2        2      3\n",
       "3        3      5\n",
       "4        4      4\n",
       "5        5      5\n",
       "6        6      0\n",
       "7        7      6\n",
       "8        8      4\n",
       "9        9      6\n",
       "10      10      6\n",
       "11      11      3\n",
       "12      12      3\n",
       "13      13      6\n",
       "14      14      6\n",
       "15      15      3\n",
       "16      16      3\n",
       "17      17      6\n",
       "18      18      6\n",
       "19      19      6\n",
       "20      20      0\n",
       "21      21      3\n",
       "22      22      6\n",
       "23      23      4\n",
       "24      24      6\n",
       "25      25      5\n",
       "26      26      3\n",
       "27      27      6\n",
       "28      28      0\n",
       "29      29      5\n",
       "...    ...    ...\n",
       "7148  7148      5\n",
       "7149  7149      6\n",
       "7150  7150      5\n",
       "7151  7151      4\n",
       "7152  7152      5\n",
       "7153  7153      2\n",
       "7154  7154      6\n",
       "7155  7155      4\n",
       "7156  7156      6\n",
       "7157  7157      3\n",
       "7158  7158      2\n",
       "7159  7159      5\n",
       "7160  7160      5\n",
       "7161  7161      3\n",
       "7162  7162      6\n",
       "7163  7163      0\n",
       "7164  7164      4\n",
       "7165  7165      3\n",
       "7166  7166      3\n",
       "7167  7167      3\n",
       "7168  7168      0\n",
       "7169  7169      3\n",
       "7170  7170      0\n",
       "7171  7171      4\n",
       "7172  7172      3\n",
       "7173  7173      2\n",
       "7174  7174      4\n",
       "7175  7175      3\n",
       "7176  7176      0\n",
       "7177  7177      2\n",
       "\n",
       "[7178 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_index =[int(i) for i in range(0,X_test.shape[0])]\n",
    "id_index=np.array(id_index)\n",
    "id_index=id_index.reshape(-1,1)\n",
    "print(id_index.shape,y_test_pred.shape)\n",
    "results = np.stack([id_index, y_test_pred],axis=1)\n",
    "results =results.reshape(-1,2,)\n",
    "results =results.astype(np.int)\n",
    "\n",
    "import time\n",
    "\n",
    "submission_file_name = RUN_MACHINE + \"sample_submission_wu{}.csv\".format(time.time())\n",
    "\n",
    "results = pd.DataFrame(results,columns=['id','label'])\n",
    "\n",
    "results.to_csv(submission_file_name,index=False)\n",
    "pd.read_csv(submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
